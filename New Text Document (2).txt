

pratical 1 =    Contour Plots

using PlotlyJS

plot(contour(colorscale="hot",
       z=[
         10   10.6  2.5  5.6  12
         2.5  3.12  5.12  8.12  2.5
         5.6  6.25  8.12  10.25 5.2
         6.2  1.25  3.12  6.25  10.62
         0    6.25  2.5   5.62  10
       ]
       ))
       
 ////////////////////////////////////////////////////
 pratical 2 =    Implement Fibonacci and Golden Search
 

Fibonacci Search

function f(n::int)
return (1.618^n - (1 - 1.618)^n) / sqrt(5)
end
function fibonacci_search(f, a, b, n; ϵ = 0.01)
s = (1 - √5) / (1 + √5)
ρ = 1 / (1.618 * (1 - s^(n + 1)) / (1 - s^n))
d = ρ * b + (1 - ρ) * a
yd = f(d)
for i = 1:n1
print("a: ",a,"\n")
print("b: ",b,"\n")
if i == n - 1
c = ϵ * a + (1 - ϵ) *
delse
c = ρ * a + (1 - ρ) * b
end
yc = f(c) if yc < yd
b, d, yd = d, c, 
ycelse
a, b = b, 
cend
ρ = 1 / (1.618 * (1 - s^(n - i + 1)) / (1 - s^(n - i)))
end
return a < b ? (a, b) : (b, a)
end
function f(x)
return x * x - x + 1
end
result=fibonacci_search(f,1,5,3)



Golden Search

function golden_section_search(f, a, b, n)
ρ = 1.618 - 1
d = ρ * b + (1 - ρ) * a
yd = f(d)
for i = 1:n1
print("a: ",a, "\n")
print("b: ",b, "\n")
c = ρ * a + (1 - ρ) * b
yc = f(c)
if yc <
yd
b, d, yd = d, c, 
yc
else
a, b = b,c
end
end
return a < b ? (a, b) : (b, a)
end
function 
f(x)return 
x*x end
re=golden_section_search(f,3,6,5)


////////////////////////////////////////////////////////


pratical 3 =  Implement Quadratic Fit Search.


function quadratic_fit_search(f, a, b, c, n)
       ya,yb,yc = F(a),f(b),f(c)
       for i in 1:n-3
       print(a,"\n",b,"\n",c,"\n")
       x=0.5*(ya*(b^2-c^2)+yb*(c^2-a^2)+(a^2-b^2))/(ya*(b-c)+yb*(c-a)+yc*(a-b))
       yx=f(x)
       if x>b
       if yx>yb
       c,yc=x,yx
       else
       a,ya,b,yb=b,yb,x,yx
       end
       end
       end
       return(a,b,c)
       end

function f(n)
       return n*n+2*n-1
       end
result = quadratic_fit_search(f,1,4,2,5)

///////////////////////////////////////////////////////////////////

pratical 4 = Gradient descent.

using LinearAlgebra

function gradient_descent(P,q,xo;a=0.1,maxiter=1000,e=le-5)
       x=copy(xo)
       f=x->P*x+q
       x=-f(x)
       iter=0
       while norm(x)>e||iter<=maxiter
       iter+=1
       x+=a*x
       x=-f(f)
       end
       return x
       end

p=[10.0-1]


q=[0;-10.0]

xo=Zeros(2)


/////////////////////////////////////////////////////////////////////////

pratical 5 = newton method

function g(storage,x)
       storage[1]=-2.0*(1.0-x[1])-400.0*(x[2]-x[1]^2)*x[1]
       storage[2]=200.0*(x[2]-x[1]^2)
       end

function h(storage,x)
       storage[1,1]=2.0-400.0*x[2]+1200.0*x[1]^2
       storage[1,2]=-400.0*x[1]
       end

using Optim

f(x)=(1.0-x[1])^2 +100.0*(x[2]-x[1]^2)^2

optimize(f,[0.0,0.0],LBFGS())

optimize(f,g,[0.0,0.0],LBFGS())

optimize(f,g,h,[0.0,0.0],LBFGS())


///////////////////////////////////////////////////////////////////

pratical 6 =  To Implement the Adagrad method with application, RMSprop andAdadelta.


using Flux

f(x) = 4x^2 + 3x + 2;

df(x) = gradient(f,x)[1];

abstract type DescentMethod end

mutable struct
       Adagrad <: DescentMethod
       α # learning rate
       ϵ # small value
       s # sum of squared gradient
       end

function
       init!(M::Adagrad,f,df,x)
       M.s=zeros(length(x))
       return M
       end

function step!(M::Adagrad, f, df,
       x)α, ϵ, s, g = M.α, M.ϵ, M.s, df(x)
       s=g*g
       return x - α*g ./ (sqrt.(s) .+ ϵ)
       end

M=Adagrad(0.01,0.0001,0.01)

result=step!(M,f,df,2)

////////////////////////////////////////////////////////////////////////
pratical 7 =  radial basis functions using surrogate modelling.


using Surrogates
using LinearAlgebra
f=x->x[1]*x[2]
lb=[1.0,2.0]
ub=[10.0,8.5]
x=sample(50,lb,ub,SobolSample())
y=f.(x)
my_radial_basis=RadialBasis(x,y,lb,ub)
approx=my_radial_basis((1.0,1.4))

using Surrogates
using Plots
f=x->log(x)*x^2+x^3
lb=1.0
ub=10.0
x=sample(50,lb,ub,SobolSample())
y=f.(x)
my_radial_basis=RadialBasis(x,y,lb,ub)
approx=my_radial_basis(5.4)
plot(x,y,seriestype=:scatter,label="Sampled Points",xlims=(lb,ub),legend=:top)
plot!(f,label="True function",xlims=(lb,ub),legend=:top)
plot!(my_radial_basis,label="Surrogate function",xlims=(lb,ub),legend=:top)



///////////////////////////////////////////////////////////////////////////

pratical 8 =   Gaussian Process and its applications.


using GaussianProcesses

using Random

Random.seed!

n=10;

x=2π*rand(n);

y=sin.(x)+0.05*randn(n);

mZero=MeanZero()

Kern=SE(0.0,0.0)

log=-1.0

gp = GP(x,y,mZero,kern,log)

using Plots

x=0:0.1:2π

plot(gp;obsv=false)

optimize!(gp)

plot(gp; obsv=false, label="GP posterior mean", fmt=:png)

samples = rand(gp, x, 5)

plot!(x, samples)


////////////////////////////////////////////////////



pratical 9 =    Ant Colony Optimization with 
anapplication.


using AntColony

distance_matrix=rand(10,10)

aco(distance_matrix,is_tour=true)

aco(distance_matrix,start_node=1,end_node=5)
